{
  "categories": [
    { "id": "all", "name": "All" },
    { "id": "deep-learning", "name": "Deep Learning" },
    { "id": "multimodal", "name": "Multimodal Learning" },
    { "id": "contrastive", "name": "Contrastive Learning" },
    { "id": "white-box", "name": "White-Box ML" }
  ],
  "projects": [
    {
      "id": "neural-matter",
      "title": "Neural Matter Networks",
      "category": "white-box",
      "date": "2025 - Present",
      "thumbnail": "https://i.imgur.com/TwYAtdu.png",
      "description": "Building next generation of white box neural networks architectures inspired by physical properties of matter for improved interpretability and performance.",
      "links": [
        { "type": "paper", "url": "#", "text": "Paper (Coming Soon)" }
      ],
      "details": {
        "collaborators": "MLNomads Research Team",
        "abstract": "Deep Learning 2.0: Artificial Neurons That Matter - Reject Correlation, Embrace Orthogonality. Neural Matter Networks represent a transformative approach to deep learning that incorporates principles from materials science and physics. By modeling neural networks as physical systems with properties like elasticity, conductivity, and thermal response, NMNs can adapt their topologies dynamically during training to optimize for both performance and computational efficiency.",
        "sections": [
          {
            "title": "Key Innovations",
            "content": "<ul><li>Physical property modeling of neural pathways</li><li>Dynamic topology adaptation during training</li><li>Material-inspired regularization techniques</li><li>Energy-efficient computation through targeted pathway activation</li><li>Enhanced interpretability through physics-inspired representations</li></ul>"
          },
          {
            "title": "Current Status",
            "content": "Our initial experiments demonstrate that NMNs achieve comparable accuracy to traditional architectures while requiring 30% fewer parameters. We are currently exploring applications in computer vision, natural language understanding, and multimodal learning tasks."
          }
        ]
      }
    },
    {
      "id": "simo2",
      "title": "SimO2: Cosmos-Inspired Anchor-Free Contrastive Loss",
      "category": "contrastive",
      "date": "2025 - Present",
      "thumbnail": "https://i.imgur.com/TwYAtdu.png",
      "description": "Novel contrastive learning loss function inspired by cosmic principles that improves representation learning by rejecting correlation and embracing orthogonality.",
      "links": [
        { "type": "repository", "url": "#", "text": "Repository (Coming Soon)" }
      ],
      "details": {
        "abstract": "SimO2 is a novel contrastive loss function that draws inspiration from cosmic principles to create more effective representations in deep learning models. Unlike traditional contrastive losses that rely on anchor-positive-negative triplets, SimO2 takes a fundamentally different approach by embracing orthogonality rather than just minimizing correlation.",
        "sections": [
          {
            "title": "Key Features",
            "content": "<ul><li>Anchor-free design that simplifies training</li><li>Orthogonality-focused optimization for better feature separation</li><li>Improved efficiency in high-dimensional spaces</li><li>Self-adjusting margin mechanism</li><li>Compatible with existing architectures and training pipelines</li></ul>"
          },
          {
            "title": "Applications",
            "content": "SimO2 has shown promising results in various representation learning tasks, including image classification, few-shot learning, and multimodal alignment. Our experiments demonstrate that models trained with SimO2 achieve better generalization and transfer learning capabilities compared to traditional contrastive methods."
          }
        ]
      }
    },
    {
      "id": "afcl",
      "title": "Unifying the Latent Space using AFCL and SimO2 Loss",
      "category": "multimodal",
      "date": "2025 - Present",
      "thumbnail": "https://i.imgur.com/TwYAtdu.png",
      "description": "Research on creating unified latent space representations for improved performance in multimodal and multilingual tasks.",
      "links": [
        { "type": "publication", "url": "#", "text": "Publication (Coming Soon)" }
      ],
      "details": {
        "abstract": "This research addresses the challenge of creating unified representations across different modalities and languages. We propose a framework that combines Anchor-Free Contrastive Learning (AFCL) with our SimO2 loss to align varied inputs into a coherent latent space, enabling more effective cross-modal and cross-lingual transfer.",
        "sections": [
          {
            "title": "Methodology",
            "content": "Our approach uses a novel alignment technique that maps inputs from different modalities (text, images, audio) or different languages into a unified latent space where semantic similarities are preserved regardless of the source modality or language. This is achieved through our SimO2 loss function that optimizes for orthogonality rather than mere correlation reduction."
          },
          {
            "title": "Results",
            "content": "Preliminary results show significant improvements in cross-modal and cross-lingual transfer tasks, with particularly strong performance in zero-shot scenarios. Models trained with our unified latent space approach demonstrate better generalization capabilities and more robust performance across diverse inputs."
          }
        ]
      }
    },
    {
      "id": "yatclr",
      "title": "YatCLR: Simpler Framework for Fine-Grained Contrastive Learning",
      "category": "contrastive",
      "date": "2025 - Present",
      "thumbnail": "https://i.imgur.com/TwYAtdu.png",
      "description": "A more efficient approach to contrastive learning for visual representations with improved discrimination capabilities.",
      "links": [
        { "type": "preprint", "url": "#", "text": "Preprint (Coming Soon)" }
      ],
      "details": {
        "abstract": "YatCLR (Yet Another Tool for Contrastive Learning of Representations) introduces a simplified yet powerful framework for fine-grained contrastive learning. By reimagining the core mechanisms of contrastive learning, YatCLR achieves better discrimination between similar but distinct concepts while maintaining computational efficiency.",
        "sections": [
          {
            "title": "Innovations",
            "content": "<ul><li>Streamlined contrastive learning pipeline with fewer components</li><li>Adaptive sampling strategy for more informative learning</li><li>Fine-grained feature extraction focused on discriminative attributes</li><li>Reduced computational requirements compared to existing methods</li></ul>"
          },
          {
            "title": "Applications",
            "content": "YatCLR has been successfully applied to image classification tasks with fine-grained categories (such as species identification), yielding a 15% improvement in discrimination accuracy compared to standard contrastive learning approaches while using 40% less compute resources."
          }
        ]
      }
    },
    {
      "id": "many-hot",
      "title": "Many-Hot Encoding",
      "category": "deep-learning",
      "date": "2025 - Present",
      "thumbnail": "https://i.imgur.com/TwYAtdu.png",
      "description": "Novel encoding technique that extends one-hot encoding for improved representation of categorical variables in machine learning models.",
      "links": [
        { "type": "code", "url": "#", "text": "Code (Coming Soon)" }
      ],
      "details": {
        "abstract": "Many-Hot Encoding represents a fundamental rethinking of how categorical variables are represented in machine learning models. Unlike traditional one-hot encoding which assigns a single '1' value with all other values being '0', Many-Hot Encoding utilizes a distributed representation that captures subtle relationships between categories.",
        "sections": [
          {
            "title": "Approach",
            "content": "<ul><li>Multi-dimensional encoding space that reflects semantic relationships</li><li>Learnable encoding patterns optimized during training</li><li>Compact representation that scales efficiently with large category spaces</li><li>Compatibility with existing model architectures</li></ul>"
          },
          {
            "title": "Benefits",
            "content": "Our experiments show that Many-Hot Encoding significantly improves model performance on tasks with large categorical spaces, reducing overfitting and improving generalization. The approach is particularly effective for categorical variables with inherent hierarchical structure or semantic relationships."
          }
        ]
      }
    },
    {
      "id": "mind-cosmos",
      "title": "Mind and Cosmos: Towards Cosmos-Inspired Activation-Free Deep Learning",
      "category": "deep-learning",
      "date": "2025 - Present",
      "thumbnail": "https://i.imgur.com/TwYAtdu.png",
      "description": "Exploring novel activation-free neural network architectures inspired by cosmic principles for more efficient and interpretable deep learning.",
      "links": [
        { "type": "publication", "url": "#", "text": "Publication (Coming Soon)" }
      ],
      "details": {
        "abstract": "This research challenges the fundamental need for activation functions in neural networks by drawing inspiration from cosmic organization principles. We explore how direct linear transformations, when properly structured and constrained, can achieve comparable or superior performance to traditional networks while offering greater interpretability and efficiency.",
        "sections": [
          {
            "title": "Key Concepts",
            "content": "Our approach replaces traditional activation functions with carefully designed linear transformation patterns inspired by natural organizing principles seen in cosmic structures. By structuring these transformations according to specific constraints derived from physics and information theory, we achieve non-linear mapping capabilities without explicit activation functions."
          },
          {
            "title": "Implications",
            "content": "Activation-free networks offer several advantages: they are more interpretable since their operation can be expressed entirely through linear algebra, they avoid vanishing/exploding gradient problems inherent to some activation functions, and they provide new theoretical insights into representation learning. Early experiments show promising results on image classification and natural language understanding tasks."
          }
        ]
      }
    },
    {
      "id": "atmospheric-visibility",
      "title": "Multimodal System for In-flight Atmospheric Visibility Estimation",
      "category": "multimodal",
      "date": "2023 - 2024",
      "thumbnail": "https://i.imgur.com/TwYAtdu.png",
      "description": "Collaboration with the Federal Aviation Administration to develop advanced visibility estimation systems for aviation safety.",
      "links": [
        { "type": "paper", "url": "#", "text": "Paper" }
      ],
      "details": {
        "collaborators": "Rowan University, Federal Aviation Administration",
        "funding": "FAA Research Grant",
        "abstract": "This research addresses the critical challenge of accurately estimating atmospheric visibility conditions during flight operations. We developed a multimodal approach that combines visual information from cameras with other sensor data to provide robust visibility estimates in various weather conditions.",
        "sections": [
          {
            "title": "Technical Approach",
            "content": "Our system integrates RGB camera data with additional sensor inputs using a novel fusion architecture. We utilized X-Plane simulation software to create a comprehensive training dataset that spans diverse weather conditions and visibility ranges. The deep learning model was designed to handle the inherent uncertainty in visibility estimation while providing reliable metrics for pilot decision-making."
          },
          {
            "title": "Impact",
            "content": "The developed system demonstrates significant improvements over existing methods, achieving a mean absolute error of less than 0.5km in visibility estimation across challenging scenarios. This work contributes to aviation safety by providing pilots with more accurate information about visibility conditions, especially in rapidly changing or degraded visual environments."
          }
        ]
      }
    }
  ]
}
